#!/usr/bin/env python

import os
import sys
import logging
import argparse
import pkg_resources
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from numpy import nan

from peppercornenumerator import CondensationError
from peppercornenumerator import PolymerizationError

from nuskell import translate, verify, NuskellExit, __version__
from nuskell.objects import clear_memory
from nuskell.verifier import modular_bisimulation
from nuskell.crnutils import parse_crn_string, Reaction
from nuskell.crnutils import split_reversible_reactions, removeSpecies

def compare_schemes(reactions, schemedir,
                    crn_name=True,
                    pc_args=None,
                    vnotions=['pathway', 'bisimulation'],
                    modular=False,
                    vtime=30,
                    cmp_ecrn_size=True,
                    cmp_total_nuc=True,
                    verbose=0):
    """Compare schemes for (multiple) CRNs.

    Arguments:
      reactions (list[str]): A list of CRN stings.
      schemedir (str): A path to a directory with translation schemes.
      vtime (int): Timeout of verification [seconds]
      args (argparse()): An object that contains arguments for peppercorn.

    Note: This function contains hacks ... not production ready
      * reject-remote hack for soloveichik-like schemes
      * number of nucleotides is wrong for schemes with history domains.

    """

    plotdata = []  # Scheme, CRN, Cost, Speed
    for scheme in sorted(os.listdir(schemedir)):
        if scheme[-3:] != '.ts':
            logging.warning("Ignoring file: {}".format(args.ts_dir + scheme))
            continue
        for (crn, crn_name) in reactions:
            if crn_name:
                current = [scheme, str(crn_name)]
            else:
                current = [scheme, crn]

            fcrn, fs = parse_crn_string(crn)

            # formal chemical reaction module
            fcrm = map(lambda x: split_reversible_reactions([x]), fcrn) 
            fcrn = split_reversible_reactions(fcrn)

            logging.info("")
            logging.info("Translating using {}".format(scheme))
            logging.info("Formal CRN:")
            for r in crn.split('\n'):
                logging.info(" {}".format(r))

            clear_memory()
            try:
                solution, modules = translate(crn, schemedir + scheme,
                                              modular = modular,
                                              verbose = (verbose > 2))
            except NuskellExit as e:
                logging.error(e)
                logging.error("Exiting translation. [{}]".format(scheme))
                logging.error("Formal CRN:")
                for r in crn.split('\n'):
                    logging.error(" {}".format(r))
                current.extend([None] * len(vnotions) + [None, None, None])
                plotdata.append(current)
                continue

            fuels = solution.fuel_complexes
            signals = solution.signal_complexes

            semantics = ['d'] if pc_args.enum_detailed else ['c']
            try:
                solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
            except PolymerizationError as e:
                # NOTE: Many PolymerizationErrors are easiest to fix with
                # --reject-remote enumeration semantics, but that is not a
                # guarantee it that it will work.
                logging.warning("Changing enumeration parameters to reject-remote [{}]".format(
                    scheme))
                logging.warning("Formal CRN:")
                for r in crn.split('\n'):
                    logging.warning(" {}".format(r))
                try:
                    pc_args.reject_remote = True
                    solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
                    semantics.append('rr')
                    pc_args.reject_remote = False
                except PolymerizationError as e:
                    logging.error(e)
                    logging.error("Insufficient enumeration parameters. [{}]".format(scheme))
                    logging.error("Formal CRN:")
                    for r in crn.split('\n'):
                        logging.error(" {}".format(r))
                    current.extend([None] * len(vnotions) + [None, None, None])
                    plotdata.append(current)
                    continue
            except CondensationError as e:
                logging.error(e)
                logging.error("Condensation error. [{}]".format(scheme))
                logging.error("Formal CRN:")
                for r in crn.split('\n'):
                    logging.error(" {}".format(r))
                current.extend([None] * len(vnotions) + [None, None, None])
                plotdata.append(current)
                continue

            if not solution.reactions:
                logging.error("No reactions have been enumerated. [{}]".format(scheme))
                logging.error("Formal CRN:")
                for r in crn.split('\n'):
                    logging.error(" {}".format(r))
                current.extend([None] * len(vnotions) + [None, None, None])
                plotdata.append(current)
                continue

            current.append(semantics)

            interpret = solution.interpret_species(fs, prune=True)

            icrn = []
            # Implementation CRN is an enumerated CRN after regex-complexes have
            # been removed.
            for r in solution.reactions:
                logging.debug("{} [{} {} - {}]".format(r, r.rate, r.rateunits, r.rtype))
                rxn = Reaction(map(str, r.reactants), map(str, r.products), r.rate.constant, 0)
                icrn.append(rxn)

            # IMPLEMENTATION DETAILS
            logging.info("Enumerated system: {} species, {} reactions".format(len(solution.complexes), len(icrn)))
            logging.info("  {} signal species".format(len([c for c in solution.complexes if c.name in interpret.keys()])))
            logging.info("  {} fuel species".format(len([c for c in solution.complexes if c.name in map(str, fuels)])))
            logging.info("  {} intermediate species".format(len([c for c in solution.complexes if c.name not in (interpret.keys() + map(str, fuels))])))
            logging.info("Number of distinct strands in the system: {}".format(len(solution.strands)))
            logging.info("Length of all distinct strands in the system: {}".format(sum( sum(map(lambda d: d.length, s)) for s in solution.strands.values())))

            # NOTE: New code.. to do the module enumeration:
            if modular:
                seen_reactions = set()
                all_reactions = set(solution.reactions)

                module_crns = []
                for e, module in enumerate(modules):
                    # first, replace history complexes with their interpretation!
                    initials = map(str, module.complexes)
                    for cplx in module.complexes:
                        # TODO quite inefficient loops
                        for k, v in interpret.items():
                            if (cplx.name in v) and k != cplx.name:
                                [newc] = solution.selected_complexes([k])
                                module.add_complex(newc, solution.get_complex_concentration(newc))
                                if module.has_complex(cplx):
                                    module.rm_complex(cplx)

                    # then, enumerate!
                    if 'rr' in semantics:
                        pc_args.reject_remote = True
                        module.enumerate_reactions(pc_args, 
                                condensed = not pc_args.enum_detailed,
                                prefix = 'tmp')
                        pc_args.reject_remote = False
                    else :
                        module.enumerate_reactions(pc_args, 
                                condensed = not pc_args.enum_detailed,
                                prefix = 'tmp')

                    # after enumeration, make sure there are no new 'tmp' species present.
                    for cplx in module.complexes:
                        assert cplx.name[:3] != 'tmp'

                    # append the CRN
                    mcrn = []
                    for r in module.reactions:
                        assert r in all_reactions
                        seen_reactions.add(r)
                        #logging.info("{} [{} {} - {}]".format(r, r.rate, r.rateunits, r.rtype))
                        rxn = Reaction(map(str, r.reactants), map(str, r.products), r.rate.constant, 0)
                        mcrn.append(rxn)
                    module_crns.append(mcrn)
                    #logging.info("")

                # last, identify crosstalk as the last implementation CRN (without
                # formal correspondence)
                mcrn = [] # crosstalk
                for r in all_reactions :
                    if r not in seen_reactions :
                        #logging.info("{} [{} {} - {}]".format(r, r.rate, r.rateunits, r.rtype))
                        rxn = Reaction(map(str, r.reactants), map(str, r.products), r.rate.constant, 0)
                        mcrn.append(rxn)

                # append the CRN
                if mcrn:
                    module_crns.append(mcrn)

                icrns = map(lambda x: removeSpecies(x, map(str, fuels)), module_crns)

            # VERIFICATION
            vcrn = removeSpecies(icrn, map(str,fuels))
            for meth in vnotions:
                if 'modular-' in meth:
                    if len(fcrm) > 1:
                        # NOTE: Temporary to fixe a bug in testModules
                        import copy
                        backup = copy.deepcopy(interpret) if interpret else None
                        v, _ = modular_bisimulation(fcrm, icrns, fs, interpret=backup, 
                                method=meth[8:], verbose=(verbose > 2), timeout=vtime)
                        #logging.warning('transfering interpretation to bisimulation')
                        #interpret = backup
                    else :
                        assert fcrn == fcrm[0]
                        v, i = verify(fcrn, vcrn, fs, interpret=interpret, method=meth[8:],
                              verbose=(args.verbose > 1), timeout=args.verify_timeout)
                else:
                    v, _ = verify(fcrn, vcrn, fs, interpret=interpret, method=meth,
                                  verbose=(verbose > 2), timeout=vtime)

                if v is True:
                    logging.info("{}: CRNs are {} equivalent.".format(v, meth))
                    current.append(v)
                elif v is False:
                    logging.info("{}: CRNs are not {} equivalent.".format(v, meth))
                    current.append(v)
                elif v is None:
                    logging.info("{}: {} verification did not terminate within {} seconds.".format(v, meth, vtime))
                    current.append(v)

            if cmp_total_nuc:
                cost = sum(sum(map(lambda d: d.length, s))
                           for s in solution.strands.values())
                current.append(cost)

            if cmp_ecrn_size:
                speed = len(icrn)
                current.append(speed)

            plotdata.append(current)

    return plotdata


def normalize(rawdata, refscheme, ns=5):
    """Normalize results to reference scheme.

      Note: This function requires a particular format of 'rawdata'.
        You might have to adapte the code if you change verification...
    """
    normdata = []
    norm_values = filter(lambda x: x[0] == refscheme, rawdata)
    for n in norm_values:  # A particular CRN
        current = filter(lambda x: x[1] == n[1], rawdata)
        for c in current:
            normdata.append(c[:ns] + [float(x) / y for x,
                                      y in zip(n[ns:], c[ns:])])

    return normdata


def single_plot(df, pfile='nuskell_compare.pdf', ts_order=None, crn_order=None):
    if not ts_order:
        ts_order = sorted(set(df['Translation scheme']),
                          key=lambda x: list(df['Translation scheme']).index(x))
    if not crn_order:
        crn_order = sorted(set(df['CRN']),
                           key=lambda x: list(df['CRN']).index(x))

    marks = ['^', '+', 'x', '<', '>', 'd', 's', 'p', '_', '*',
             '.', 'h', 'v', 'p', '1', '2', '3', '4', '8', '_']

    marks = marks[:len(ts_order)]

    seman = 'detailed' if args.enum_detailed else 'condensed'

    g = sns.lmplot(data=df, x="reactions in " + seman + " network", y="number of nucleotides",
                   hue="Translation scheme", hue_order=ts_order,
                   # col="equivalent", col_wrap=2, col_order=[True, False, 'timeout'],
                   # col="CRN", col_wrap=2, col_order=crn_order,
                   legend=False, legend_out=True,
                   # size=3.6,
                   x_jitter=0.2,
                   markers=marks,
                   fit_reg=False,
                   scatter=True)

    g = g.add_legend()  # bbox_to_anchor=(1.63, 0.53))
    plt.savefig(pfile, bbox_inches="tight")
    return


def main(args):
    """Compare multiple tranlation schemes for a given CRN. """

    # *************** #
    # Check arguments #
    # _______________ #

    if args.pyplot and (args.pyplot[-4:] not in ('.pdf', '.png', '.eps')):
        raise SystemExit('Please choose a file format (*.pdf, *png, *eps) for your plot: {}'.format(
            args.pyplot))

    if not args.modular:
        args.modular = any(map(lambda x: 'modular' in x, args.verify))

    # ***************** #
    # Process CSV input #
    # _________________ #

    if args.from_csv:
        logging.info('# Parsing data from file ... ')
        df = pd.DataFrame().from_csv(args.from_csv)

    else:
        # ***************** #
        # Process CRN input #
        # _________________ #
        if args.crn_dir:
            if args.crn_dir[-1] != '/': args.crn_dir += '/'
            logging.info("Compiling CRNs in:", args.crn_dir)
            reactions = []
            for crnfile in filter(
                    lambda x: x[-4:] == '.crn', os.listdir(args.crn_dir)):
                logging.info(' *{}'.format(crnfile))
                with open(args.crn_dir + crnfile) as fcrn:
                    react = ''
                    for l in fcrn.readlines():
                        react += l.strip() + '; '
                reactions.append((react[:-2], crnfile))
        else:
            input_crn = sys.stdin.readlines()
            input_crn = "".join(input_crn).strip()
            reactions = [(input_crn, input_crn)]
            logging.info("Compiling CRN:")
            for (rxn, n) in reactions:
                for r in rxn.split('\n'):
                    logging.info('  {}'.format(r))
            logging.info("")

        # **************** #
        # Process TS input #
        # ________________ #

        if args.ts_dir:
            if args.ts_dir[-1] != '/': args.ts_dir += '/'
            logging.info("Comparing schemes in: {}".format(args.ts_dir))
        else:
            logging.info("Comparing default schemes:")
            args.ts_dir = pkg_resources.resource_filename('nuskell', 'schemes') + '/'

        for ts in filter(lambda x: x[-3:] == '.ts',
                         sorted(os.listdir(args.ts_dir))):
            logging.info('  {}'.format(ts))

        # ***************** #
        # Process REF input #
        # _________________ #

        if args.reference and args.reference not in os.listdir(args.ts_dir):
            raise SystemExit('Reference scheme not found.')

        # ********* #
        # MAIN LOOP #
        # _________ #

        plotdata = compare_schemes(reactions, args.ts_dir,
                                   pc_args=args,
                                   cmp_ecrn_size=True,
                                   cmp_total_nuc=True,
                                   vnotions=args.verify,
                                   modular=args.modular,
                                   vtime=args.verify_timeout,
                                   verbose=args.verbose)

        # Results:
        idx = zip(zip(*plotdata)[0], zip(*plotdata)[1])
        df = pd.DataFrame(plotdata, index = idx,
                          columns = ['Translation scheme', 
                                     'CRN', 
                                     'enumerated'] + args.verify + [
                                     'number of nucleotides', 
                                     'reactions in condensed network'])

    # print 'Rawdata:'
    # print df.to_string(index=False, justify='left')
    # print df.to_latex(index=False)

    # Save to portable format:
    if args.to_csv:
        df.to_csv(path_or_buf=args.to_csv)

    # Normalize data to --reference scheme
    # TODO: remove csv dependece
    if not args.from_csv and args.reference:
        plotdata = normalize(plotdata, args.reference)
        logging.info('Normalized to {}:'.format(args.reference))
        df = pd.DataFrame(plotdata,
                          columns=[
                              'Translation scheme', 'CRN', 'enumerated'] + args.verify + [
                              'number of nucleotides', 'reactions in condensed network'])
        print df.to_string(index=False, justify='right')

    def equiv(x):
        if True in x:
            return True
        elif (nan in x) or (None in x):
            return 'timeout'
        else:
            return False

    # Add column that combines equivalence notions.
    e = map(equiv, zip(*map(lambda x: df[x], args.verify)))
    df['equivalent'] = e
    print df.to_string(index=False, justify='left')

    if args.pyplot:
        single_plot(df, pfile=args.pyplot)


def get_nuskellCMP_args(parser):
    """ A collection of arguments for Nuskell """
    parser.add_argument(
        '--version',
        action='version',
        version='%(prog)s ' +
        __version__)
    parser.add_argument("-v", "--verbose", action='count', default=0,
                        help="print verbose output. -vv increases verbosity level.")

    input = parser.add_argument_group('NuskellCMP Input Arguments')

    input.add_argument("--ts-dir", action='store', metavar='<path/to/dir>',
                       help="""Specify path to the translation scheme directory. Only files that
      have a *.ts ending will be compared.""")

    input.add_argument("--crn-dir", action='store', metavar='<path/to/dir>',
                       help="""Specify path to a CRN directory. Only files that have a *.crn
      ending will be compared.""")

    input.add_argument("--reference", action='store', metavar='<path/to/file>',
                       help="Specify a translation scheme that serves as a reference.")

    input.add_argument("--from-csv", action='store', metavar='<path/to/file>',
                       help="Read results from a *.CSV file. All other inputs are ignored.")

    default = parser.add_argument_group('NuskellCMP Output Arguments')

    default.add_argument("--pyplot", default='', action='store', metavar='<path/to/file>',
                         help="Specify name of plot file. Choose from fileformats *.pdf or *.png")

    default.add_argument("--to-csv", action='store', default='', metavar='<path/to/file>',
                         help="Print results to a *.CSV file.")

    # NOTE: changing the equivalence notions would break normalization and
    # plotting.
    default.add_argument("--verify", nargs='+', default=['bisimulation', 'pathway'],
                         action='store',
                         choices=('bisimulation', 'pathway', 'integrated', 'modular-bisimulation',
                                  'bisim-loop-search', 'bisim-depth-first', 'bisim-whole-graph',
                                  'modular-bisim-loop-search',
                                  'modular-bisim-depth-first',
                                  'modular-bisim-whole-graph'),
                         metavar='<str>',
                         help="""Specify verification methods. Choose one or more
      from: bisimulation, pathway, integrated, modular-bisimulation,
      bisim-loop-search, bisim-depth-first, bisim-whole-graph,
      modular-bisim-loop-search,
      modular-bisim-depth-first,
      modular-bisim-whole-graph.""")

    default.add_argument("--modular", action='store_true',
                         help="""After enumeration of the full system, enumerate individual CRN
      modules separately, to identify crosstalk between reactions. This is
      turned on automatically when using modular-bisimulation verification.""")

    default.add_argument("--verify-timeout", type=int, default=30, metavar='<int>',
                         help="Specify time in seconds to wait for verification to complete.")

    return parser


def get_peppercorn_args(parser):
    """Selected arguments for the peppercorn interface. """
    peppercorn = parser.add_argument_group(
        'Peppercorn Reaction Enumerator Arguments')
    peppercorn.add_argument('--max-complex-size', default=50, type=int, metavar='<int>',
                            help="""Maximum number of strands allowed in a complex (used to prevent
      polymerization)""")
    peppercorn.add_argument('--max-complex-count', default=1000, type=int, metavar='<int>',
                            help="""Maximum number of complexes that may be enumerated before the enumerator halts.""")
    peppercorn.add_argument('--max-reaction-count', default=10000, type=int, metavar='<int>',
                            help="""Maximum number of reactions that may be enumerated before the
      enumerator halts.""")

    peppercorn.add_argument('--reject-remote', action='store_true',
                            help="Discard remote toehold mediated 3-way and 4-way branch migration reactions.")
    peppercorn.add_argument('--ignore-branch-3way', action='store_true',
                            help="Ignore 3-way branch migration events during enumeration.")
    peppercorn.add_argument('--ignore-branch-4way', action='store_true',
                            help="Ignore 4-way branch migration events during enumeration.")

    # TODO: explain these options in more detail!
    peppercorn.add_argument('--release-cutoff-1-1', type=int, default=6, metavar='<int>',
                            help="""Maximum number of bases that will be released spontaneously in a
      1-1 `open` reaction""")
    peppercorn.add_argument('--release-cutoff-1-n', type=int, default=6, metavar='<int>',
                            help="""Maximum number of bases that will be released spontaneously in a
      1-n `open` reaction.""")
    peppercorn.add_argument('--release-cutoff', type=int, default=None, metavar='<int>',
                            help="""Maximum number of bases that will be released spontaneously in an
      `open` reaction, for either 1-1 or 1-n reactions (equivalent to setting
      --release-cutoff-1-1 and --release-cutoff-1-n to the same value)""")

    peppercorn.add_argument('--no-max-helix', action='store_true',
                            help="""Do not apply 'max helix at a time' semantics to 3-way branch
      migration reactions.""")

    peppercorn.add_argument('--enum-detailed', action='store_true',
                            help="Do not condense reactions into only resting complexes")

    peppercorn.add_argument('--k-slow', default=0.0, type=float, metavar='<flt>',
                            help="Unimolecular reactions slower than this rate will be discarded")

    peppercorn.add_argument('--k-fast', default=0.0, type=float, metavar='<flt>',
                            help="Unimolecular reactions slower than this rate will be marked as slow")

    return parser


if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    get_nuskellCMP_args(parser)
    get_peppercorn_args(parser)
    args = parser.parse_args()

    logger = logging.getLogger()
    if args.verbose == 1:
        logger.setLevel(logging.INFO)
    elif args.verbose == 2:
        logger.setLevel(logging.DEBUG)
    elif args.verbose >= 3:
        logger.setLevel(logging.NOTSET)

    ch = logging.StreamHandler()

    formatter = logging.Formatter('%(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    logger.addHandler(ch)

    main(args)
