#!/usr/bin/env python

import os
import sys
import signal
import argparse
import pkg_resources
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from nuskell import translate, verify, printCRN

from nuskell.parser import parse_crn_string, parse_crn_file, split_reversible_reactions
from nuskell.enumeration import TestTubePeppercornIO
from nuskell.verifier import removeSpecies

#from nuskell.objects import TestTube, TestTubeIO
#from nuskell.verifier import preprocess

class TimeoutError(Exception):
  pass

def handler(signum, frame):
  raise TimeoutError('Time over')

def compare_schemes(reactions, schemedir, 
    pc_args = None, 
    vnotions = ['pathway', 'bisimulation'],
    vtime = 30, 
    cmp_ecrn_size = True,
    cmp_total_nuc = True,
    verbose=0):
  """Compare schemes for (multiple) CRNs.

  Arguments:
    reactions <list[str]>: A list of CRN stings.
    schemedir <str>: A path to a directory with translation schemes.
    vtime <int>: Timeout of verification [seconds]
    args <argparse()>: An object that contains arguments for peppercorn.

  Note: This function contains hacks, i.e. it is not publication-ready:
    * reject-remote hack for soloveichik-like schemes
    * number of nucleotides is wrong for schemes with history domains.

  
  """

  plotdata = [] # Scheme, CRN, Cost, Speed
  for crn in reactions : 
    for scheme in os.listdir(schemedir) :
      if scheme[-3:] != '.ts' : 
        #print "# Ignoring file:", args.ts_dir + scheme
        continue

      #if scheme[0] != 's' and scheme[0] != 'q' : continue
      current = [scheme, crn]

      (fcrn, fs, cs) = parse_crn_string(crn) 
      fcrn = split_reversible_reactions(fcrn)

      #NOTE: Settings that might be subject to change later
      pc_args.REJECT_REMOTE = False
      pc_args.MAX_COMPLEX_COUNT = 10000

      print '\n# Scheme:', scheme, 'CRN:', crn
      solution, _ = translate(crn, schemedir + scheme)

      fuels = map(str, solution.present_complexes(exclude=fs))
      if cmp_total_nuc :
        # NOTE: The actual number of nucleotides is smaller for translations using history domains.
        print ' Number of Nucleotides:',
        print sum(map(len, 
          map(lambda x: x.nucleotide_sequence, 
            solution.complexes)))
            #filter(lambda x: x.name not in fs, solution.complexes))))

        cost = sum(map(len, map(lambda x: x.nucleotide_sequence, solution.complexes)))
        current.append(cost)

      # ENUMERATION
      #if scheme == 'soloveichik2010_v1.ts':
      #  print "# WARNING: changing eqivalence notion --reject-remote"
      #  pc_args.REJECT_REMOTE = True

      #if scheme == 'srinivas2017_phd.ts':# and crn == 'A + A -> A':
      #  print "# WARNING: changing eqivalence notion --reject-remote"
      #  pc_args.REJECT_REMOTE = True

      solution.enumerate_reactions(args, condensed = not args.enum_uncondensed)

      enum_crn = []
      for r in solution.reactions:
        if args.verbose:
          print r, "[{} {} - {}]".format(r.rate, r.rateunits, r.rtype)
        rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
        enum_crn.append(rxn)

      interpret = solution.interpret_species(fs, prune=True)
      icrn = []
      # Implementation CRN is an enumerated CRN after regex-complexes have been
      # removed.
      for r in solution.reactions:
        if args.verbose:
          print r, "[{} {} - {}]".format(r.rate, r.rateunits, r.rtype)
        rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
        icrn.append(rxn)

      if cmp_ecrn_size:
        print " Size of implementation network:",
        print len(icrn)
        speed = len(icrn)
        current.append(speed)

      # VERIFICATION
      vcrn = removeSpecies(icrn, fuels)
      for meth in vnotions :
        signal.signal(signal.SIGALRM, handler)
        signal.alarm(vtime)
        try :
          v, _ = verify(fcrn, vcrn, fs, interpret=interpret, method=meth,
              verbose=(verbose>1))
          if v:
            print " {}: CRNs are {} equivalent.".format(v, meth)
          else:
            print " {}: CRNs are not {} equivalent.".format(v, meth)
        except TimeoutError:
          v = None
          print " {}: {} verification did not terminate within {} seconds.".format(v, meth, vtime)
        signal.alarm(0)
        current.insert(2, v)

      plotdata.append(current)
  return plotdata

def normalize(rawdata, refscheme):
  """Normalize results to reference scheme. 

    Note: This function requires a particular format of 'rawdata'. 
      You might have to adapte the code if you change verification...
  """
  normdata = []
  norm_values = filter(lambda x: x[0] == refscheme, rawdata)
  for n in norm_values: # A particular CRN
    current = filter(lambda x: x[1] == n[1], rawdata)
    for c in current:
      normdata.append(c[:4] + [float(x)/y for x,y in zip(n[4:], c[4:])])
    
  return normdata

def plot_by_reference(df, pfile='nuskell_compare.pdf', ts_order=None):
  # This is the old version, it does not support the different markers for 
  # correct vs timeout vs incorrect.
  if not ts_order:
    ts_order = sorted(set(df['Translation scheme']))

  g = sns.PairGrid(data=df, hue='Translation scheme', size=4,
      x_vars=["size of enumerated network [#reactions]"],
      y_vars=["number of nucleotides [nt]"])
  g = g.map(plt.scatter)
  g = g.add_legend(bbox_to_anchor=(1.5, 0.8))
  plt.savefig(pfile, bbox_inches="tight")
  return

def plot_crn_by_crn(df, pfile='nuskell_compare.pdf', ts_order=None, crn_order=None):
  if not ts_order:
    ts_order = sorted(set(df['Translation scheme']))
  if not crn_order:
    crn_order = sorted(set(df['CRN']))

  def is_correct(x):
    """Check if the scheme is equivalent according to any of the notions. """
    equiv = list(x.filter(like='equivalent', axis=1).values[0])
    if True in equiv :
      return 'o'
    elif None in equiv :
      return 's'
    else :
      return 'D'

  #sns.set(style="ticks", color_codes=True)
  with sns.color_palette("hls", n_colors=len(ts_order)) :
    g = sns.FacetGrid(df, col="CRN", col_order=crn_order, col_wrap=2, sharex=False, sharey=False,
        hue='Translation scheme', hue_order=ts_order)
    g = g.map(plt.scatter, "size of enumerated network [#reactions]", "number of nucleotides [nt]")
    
    if True:
      for (crn, ax) in zip(crn_order, g.axes.flat) :
        # TODO: add a legend for 'D', 's', 'o'.
        #ax.annotate(c, xy=(10, 553))
        #ax.annotate(crn, xy=(8, 245))
        ax.set_axis_bgcolor("lightgray")
        for col, ts in enumerate(ts_order) :
          # NOTE: filter is dangerous because it may match multiple entries, however, not if you
          # match including the parenthesis.
          tcdf = df.filter(like="{}".format(ts), axis=0)
          #print 'tst', crn, ts, tcdf.values
          ax.scatter("size of enumerated network [#reactions]", "number of nucleotides [nt]", 
              data=tcdf, marker=is_correct(tcdf), c=sns.color_palette()[col])
          #sns.regplot("size of enumerated network [#reactions]", "number of nucleotides [nt]", data=tcdf, 
          #    ax=ax, marker=is_correct(tcdf), fit_reg=False)


    g = g.add_legend()#bbox_to_anchor=(1.05, 1), borderaxespad=0.)
    #plt.show()
    plt.savefig(pfile, bbox_inches="tight")

  # OLDCODE:
  # row, col = g.axes.shape
  # for i in range(row):
  #   for j in range(col):
  #     ax = g.axes[i, j]
  #     ax.set_axis_bgcolor("lightgray")
  # g.axes[0,0].annotate("Test1", xy=(8, 245))
  # g.axes[0,1].annotate("Test2", xy=(16, 553))

def main(args):
  """Compare multiple tranlation schemes for a given CRN. """
  # ***************** #
  # Process CRN input #
  # _________________ #

  if args.plot and (args.plot[-4:] != '.pdf' and args.plot[-4:] != '.png'):
    raise SystemExit('Please choose a file format (*.pdf, *png) for your plot: {}'.format(args.plot))

  if args.crn_dir:
    print "Compiling CRNs in:", args.crn_dir
    reactions = []
    for crnfile in filter(lambda x: x[-4:] == '.crn', os.listdir(args.crn_dir)):
      print ' *', crnfile
      with open(args.crn_dir+crnfile) as fcrn :
        react = ''
        for l in fcrn.readlines():
          react += l.strip() + '; '
      reactions.append(react[:-2])
      #(fcrn, fs, cs) = parse_crn_file(args.crn_dir+crnfile)
      #reactions.append(fcrn)
  else :
    input_crn = sys.stdin.readlines()
    input_crn = "".join(input_crn)
    reactions = [input_crn]
    print "Compiling CRN:"
    for rxn in reactions: 
      print ' *', rxn

  #else :
  #  # A few common tests to find bugs in reaction schemes
  #  reactions = [
  #      'A -> ', 
  #      '-> B',
  #      'A -> B', 
  #      'A <=> B', 
  #      'A -> A + A', 
  #      'A + A -> A', 
  #      'A + B -> B + B' ]

  #  networks = [
  #      'A + B -> B + B; B + C -> C + C; A + C -> A + A',
  #      'A <=> A + A; A + B -> B + B; B -> ; A + C -> ; C <=> C + C',
  #      'A <=> X; B + X <=> Y + A; C + Y + X <=> Z + B + A']
  #  reactions += networks


  # ***************** #
  # Process DIR input #
  # _________________ #
  
  if args.ts_dir :
    print "Comparing schemes in:", args.ts_dir
  else :
    print "Comparing default schemes:" 
    args.ts_dir = pkg_resources.resource_filename('nuskell', 'schemes') + '/'

  for ts in filter(lambda x: x[-3:] == '.ts', os.listdir(args.ts_dir)):
    print ' *', ts

  # ***************** #
  # Process REF input #
  # _________________ #
  
  if args.reference and args.reference not in os.listdir(args.ts_dir):
    raise Exception('Reference scheme not found.')

  # ********* #
  # MAIN LOOP #
  # _________ #
  
  # Scheme, CRN, Cost, Speed
  plotdata = compare_schemes(reactions, args.ts_dir,
      pc_args = args,
      cmp_ecrn_size = True,
      cmp_total_nuc = True,
      vnotions = ['pathway', 'bisimulation'],
      vtime = args.verify_timeout,
      verbose=args.verbose)

  # Results:
  print 'Rawdata:'
  for p in plotdata: print '', p

  # Normalize data to --reference scheme
  if args.reference :
    plotdata = normalize(plotdata, args.reference)
    print 'Normalized to {}:'.format(args.reference)
    for p in plotdata: print '', p
    idx = zip(zip(*plotdata)[0], zip(*plotdata)[1])
    df = pd.DataFrame(plotdata, index=idx, 
        columns=['Translation scheme', 'CRN', 'bisimulation equivalent', 
          'pathway equivalent', 'number of nucleotides [nt]', 'size of enumerated network [#reactions]'])
    if args.plot :
      plot_by_reference(df, pfile=args.plot)

  elif args.plot :
    idx = zip(zip(*plotdata)[0], zip(*plotdata)[1])
    df = pd.DataFrame(plotdata, index=idx, 
        columns=['Translation scheme', 'CRN', 'bisimulation equivalent', 
          'pathway equivalent', 'number of nucleotides [nt]', 'size of enumerated network [#reactions]'])
    plot_crn_by_crn(df, pfile=args.plot)

def get_nuskellCMP_args(parser) :
  """ A collection of arguments for Nuskell """

  parser.add_argument("--ts_dir", action = 'store',
      help="Specify path to the translation scheme directory. " + \
        "Only files that have a *.ts ending will be compared.")

  parser.add_argument("--crn_dir", action = 'store',
      help="Specify path to a CRN directory. " + \
        "Only files that have a *.crn ending will be compared.")

  parser.add_argument("--reference", action = 'store',
      help="Specify a translation scheme that serves as a reference.")

  parser.add_argument("--verify", default='', action = 'store',
      help="Specify the verification method: \
          (bisimulation, pathway, integrated, bisim-loop-search,\
          bisim-depth-first, bisim-whole-graph)") 

  parser.add_argument("--verify-timeout", type=int, default=30,
      help="Specify time [seconds] to wait for verification to complete.")

  parser.add_argument("--plot", default='nuskell_compare.pdf', action = 'store',
      help="Specify name of plot file. Choose from fileformats *.pdf or *.png")

  parser.add_argument("-v", "--verbose", action='count', default=0,
      help="Print more output (-vv for extra debugging information)")

  return

def get_peppercorn_args(parser):
  """Selected arguments for the peppercorn interface. """
  parser.add_argument('--max-complex-size', default=100, type=int, dest='MAX_COMPLEX_SIZE', 
      metavar='<int>',
      help="Peppercorn: Maximum number of strands allowed in a complex" + \
          "(used to prevent polymerization)")
  parser.add_argument('--max-complex-count', default=1000, type=int, dest='MAX_COMPLEX_COUNT',
      metavar='<int>',
      help="Peppercorn: Maximum number of complexes that may be enumerated" + \
          "before the enumerator halts.")
  parser.add_argument('--max-reaction-count', default=10000, type=int, dest='MAX_REACTION_COUNT',
      metavar='<int>',
      help="Peppercorn: Maximum number of reactions that may be enumerated " + \
          "before the enumerator halts.")

  parser.add_argument('--reject-remote', action='store_true', dest='REJECT_REMOTE',
      help="Peppercorn: Discard remote toehold mediated 3-way and 4-way branch migration reactions.")
  parser.add_argument('--ignore-branch-3way', action='store_true',
      help="Peppercorn: Ignore 3-way branch migration events during enumeration.")
  parser.add_argument('--ignore-branch-4way', action='store_true',
      help="Peppercorn: Ignore 4-way branch migration events during enumeration.")

  # TODO: explain these options in more deatail!
  parser.add_argument('--release-cutoff-1-1', type=int, default=6, dest='RELEASE_CUTOFF_1_1',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously "+\
          "in a 1-1 `open` reaction" )
  parser.add_argument('--release-cutoff-1-n', type=int, default=6, dest='RELEASE_CUTOFF_1_N',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously " + \
          "in a 1-n `open` reaction.")
  parser.add_argument('--release-cutoff', type=int, default=None, dest='RELEASE_CUTOFF',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously " +\
          "in an `open` reaction, for either 1-1 or 1-n reactions (equivalent to setting " + \
          "--release-cutoff-1-1 and --release-cutoff-1-n to the same value)")

  parser.add_argument('--no-max-helix', action='store_true',
      help="Peppercorn: Don't apply 'max helix at a time' semantics to " +\
          "3-way branch migration reactions.")
  parser.add_argument('--legacy-unzip', action='store_true', dest='LEGACY_UNZIP',
      help="Peppercorn: Apply legacy 'UNZIP=True' behavior. Note: --legacy-unzip" + \
      "mode will have no effect, if max helix semantics are disabled (--no-max-helix)")

  # NOTE: Output formatting: this option is not directly passed on to peppercorn
  parser.add_argument('--enum-uncondensed', action='store_true',
      help="Peppercorn: Don't condense reactions into only resting complexes")

  # NOTE: The option --no-rates was removed, because peppercorn always computes
  # rates, but you may choose to ignore them for condensed reaction graphs. 
  # k-fast enables to prune the condensed network, leaving the default of 0 M/s, has
  # the same effect.

  parser.add_argument('--k-slow', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be discarded")

  parser.add_argument('--k-fast', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be marked as slow")

  return

if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  get_nuskellCMP_args(parser)
  get_peppercorn_args(parser)
  args = parser.parse_args()

  main(args)

