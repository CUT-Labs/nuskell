#!/usr/bin/env python

import os
import sys
import argparse
import pkg_resources
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from numpy import nan

from nuskell import translate, verify
from nuskell.parser import parse_crn_string, split_reversible_reactions
from nuskell.enumeration import TestTubePeppercornIO
from nuskell.verifier import removeSpecies

def compare_schemes(reactions, schemedir, 
    crn_name = True,
    pc_args = None, 
    vnotions = ['pathway', 'bisimulation'],
    vtime = 30, 
    cmp_ecrn_size = True,
    cmp_total_nuc = True,
    verbose=0):
  """Compare schemes for (multiple) CRNs.

  Arguments:
    reactions (list[str]): A list of CRN stings.
    schemedir (str): A path to a directory with translation schemes.
    vtime (int): Timeout of verification [seconds]
    args (argparse()): An object that contains arguments for peppercorn.

  Note: This function contains hacks ... not production ready
    * reject-remote hack for soloveichik-like schemes
    * number of nucleotides is wrong for schemes with history domains.
  
  """

  plotdata = [] # Scheme, CRN, Cost, Speed
  for (crn,crn_name) in reactions : 
    for scheme in os.listdir(schemedir) :
      if scheme[-3:] != '.ts' : 
        print "\n# Ignoring file:", args.ts_dir + scheme
        continue

      if crn_name :
        current = [scheme, str(crn_name)]
      else :
        current = [scheme, crn]

      fcrn, fs, _, _ = parse_crn_string(crn) 
      fcrn = split_reversible_reactions(fcrn)

      print "\n# -------"
      print '# Scheme:', scheme, 'CRN:', crn
      print "# -------"
      try :
        solution, _ = translate(crn, schemedir + scheme)
      except SystemExit, e:
        print e
        current.extend([None, None, None, None, None])
        plotdata.append(current)
        continue

      fuels = map(str, solution.present_complexes(exclude=fs))

      # NOTE: Peppercorn can raise a variety of errors, but almost all of them
      # come down to problems with --reject-remote semantics... here are a few
      # examples:
      notion = ['d'] if args.enum_detailed else ['c']
      try :
        solution.enumerate_reactions(pc_args, condensed = not args.enum_detailed)
      except RuntimeError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except TypeError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except IndexError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except Exception, e:
        # Scheme: lakin2016_3D.ts CRN: A + A -> B + A
        # File "../peppercorn/utils.py", line 879, in check_structure
        # Exception: In complex 17029, incoherent structure at (0, 5) -> (1, 0)
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False

      current.append(notion)

      interpret = solution.interpret_species(fs, prune=True)

      icrn = []
      # Implementation CRN is an enumerated CRN after regex-complexes have been removed.
      for r in solution.reactions:
        if args.verbose:
          print r, "[{} {} - {}]".format(r.rate, r.rateunits, r.rtype)
        rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
        icrn.append(rxn)

      # IMPLEMENTATION DETAILS
      print "# Enumerated system: {} species, {} reactions".format(
          len(solution.complexes), len(icrn))
      print "#  - {} signal species".format(
          len([c for c in solution.complexes if c.name in interpret.keys()]))
      print "#  - {} fuel species".format(
          len([c for c in solution.complexes if c.name in map(str, fuels)]))
      print "#  - {} intermediate species".format(
          len([c for c in solution.complexes if c.name not in (interpret.keys() + map(str,fuels))]))
      print '# Number of distinct strands in the system:', len(solution.strands)
      print '# Length of all distinct strands in the system:', sum(
          sum(map(lambda d: d.length, s)) for s in solution.strands.values())

      # VERIFICATION
      vcrn = removeSpecies(icrn, fuels)
      for meth in vnotions :
        v, _ = verify(fcrn, vcrn, fs, interpret=interpret, method=meth,
            timeout=vtime, verbose=(verbose>1))
        if v is True:
          print "# {}: CRNs are {} equivalent.".format(v, meth)
          current.append(v)
        elif v is False:
          print "# {}: CRNs are not {} equivalent.".format(v, meth)
          current.append(v)
        elif v is None:
          print "# {}: {} verification did not terminate within {} seconds.".format(v, meth, vtime)
          current.append(v)
          #current.append('- [{} s]'.format(vtime))

      if cmp_total_nuc :
        cost = sum(sum(map(lambda d: d.length, s)) for s in solution.strands.values())
        current.append(cost)

      if cmp_ecrn_size:
        speed = len(icrn)
        current.append(speed)

      plotdata.append(current)
  return plotdata

def normalize(rawdata, refscheme, ns=5):
  """Normalize results to reference scheme. 

    Note: This function requires a particular format of 'rawdata'. 
      You might have to adapte the code if you change verification...
  """
  normdata = []
  norm_values = filter(lambda x: x[0] == refscheme, rawdata)
  for n in norm_values: # A particular CRN
    current = filter(lambda x: x[1] == n[1], rawdata)
    for c in current:
      normdata.append(c[:ns] + [float(x)/y for x,y in zip(n[ns:], c[ns:])])
    
  return normdata

def single_plot(df, pfile='nuskell_compare.pdf', ts_order=None, crn_order=None):
  if not ts_order:
    ts_order = sorted(set(df['Translation scheme']), 
        key=lambda x: list(df['Translation scheme']).index(x))
  if not crn_order:
    crn_order = sorted(set(df['CRN']),
        key=lambda x: list(df['CRN']).index(x))

  marks=['^','+','x','<','>','d','s','p','_', '*', 
      '.', 'h', 'v', 'p', '1', '2', '3', '4', '8', '_']

  marks = marks[:len(ts_order)]

  g = sns.lmplot(data=df, x="reactions in condensed network", y="number of nucleotides", 
      hue="Translation scheme", hue_order = ts_order,
      #col="equivalent", col_wrap=2, col_order=[True, False, 'timeout'],
      #col="CRN", col_wrap=2, col_order=crn_order,
      legend=False, legend_out=True,
      #size=3.6,
      x_jitter=0.2,
      markers=marks,
      fit_reg=False,
      scatter=True)

  g = g.add_legend() #bbox_to_anchor=(1.63, 0.53))
  plt.savefig(pfile, bbox_inches="tight")
  return

def main(args):
  """Compare multiple tranlation schemes for a given CRN. """

  # *************** #
  # Check arguments #
  # _______________ #

  if args.pyplot and (args.pyplot[-4:] not in ('.pdf', '.png', '.eps')):
    raise SystemExit('Please choose a file format (*.pdf, *png, *eps) for your plot: {}'.format(
      args.pyplot))

  # ***************** #
  # Process CSV input #
  # _________________ #

  if args.from_csv :
    print '# Parsing data from file ... '
    df = pd.DataFrame().from_csv(args.from_csv)

  else:
    # ***************** #
    # Process CRN input #
    # _________________ #
    if args.crn_dir:
      print "Compiling CRNs in:", args.crn_dir
      reactions = []
      for crnfile in filter(lambda x: x[-4:] == '.crn', os.listdir(args.crn_dir)):
        print ' *', crnfile
        with open(args.crn_dir+crnfile) as fcrn :
          react = ''
          for l in fcrn.readlines():
            react += l.strip() + '; '
        reactions.append((react[:-2], crnfile))
    else :
      input_crn = sys.stdin.readlines()
      input_crn = "".join(input_crn)
      reactions = [(input_crn, input_crn)]
      print "Compiling CRN:"
      for (rxn, n) in reactions: 
        print ' *', rxn

    # **************** #
    # Process TS input #
    # ________________ #
    if args.ts_dir :
      print "Comparing schemes in:", args.ts_dir
    else :
      print "Comparing default schemes:" 
      args.ts_dir = pkg_resources.resource_filename('nuskell', 'schemes') + '/'

    for ts in filter(lambda x: x[-3:] == '.ts', os.listdir(args.ts_dir)):
      print ' *', ts

    # ***************** #
    # Process REF input #
    # _________________ #
    
    if args.reference and args.reference not in os.listdir(args.ts_dir):
      raise Exception('Reference scheme not found.')

    # ********* #
    # MAIN LOOP #
    # _________ #

    plotdata = compare_schemes(reactions, args.ts_dir,
        pc_args = args,
        cmp_ecrn_size = True,
        cmp_total_nuc = True,
        vnotions = ['pathway', 'bisimulation'],
        vtime = args.verify_timeout,
        verbose=args.verbose)

    # Results:
    idx = zip(zip(*plotdata)[0], zip(*plotdata)[1])
    df = pd.DataFrame(plotdata, index=idx, 
        columns=[
          'Translation scheme', 'CRN', 
          'enumerated',
          'pathway', 
          'bisimu', 
          'number of nucleotides', 
          'reactions in condensed network'])

  #print 'Rawdata:'
  #print df.to_string(index=False, justify='left')
  #print df.to_latex(index=False)

  # Save to portable format:
  if args.to_csv:
    df.to_csv(path_or_buf=args.to_csv)

  # Normalize data to --reference scheme
  # TODO: remove csv dependece
  if not args.from_csv and args.reference :
    plotdata = normalize(plotdata, args.reference)
    print 'Normalized to {}:'.format(args.reference)
    df = pd.DataFrame(plotdata, 
        columns=[
          'Translation scheme', 'CRN', 
          'enumerated',
          'pathway', 
          'bisimu', 
          'number of nucleotides', 
          'reactions in condensed network'])
    print df.to_string(index=False, justify='right')

  def equiv((x,y)):
    if True in (x,y) :
      return True
    elif (nan in (x,y)) or (None in (x,y)) :
      return 'timeout'
    else :
      return False

  # Add column that combines pathway and bisimulation notion 
  e = map(equiv, zip(df['pathway'], df['bisimu']))
  df['equivalent'] = e
  print df.to_string(index=False, justify='left')

  if args.pyplot :
    single_plot(df, pfile=args.pyplot)

def get_nuskellCMP_args(parser) :
  """ A collection of arguments for Nuskell """

  parser.add_argument("--ts-dir", action = 'store',
      help="Specify path to the translation scheme directory. " + \
        "Only files that have a *.ts ending will be compared.")

  parser.add_argument("--crn-dir", action = 'store',
      help="Specify path to a CRN directory. " + \
        "Only files that have a *.crn ending will be compared.")

  parser.add_argument("--reference", action = 'store',
      help="Specify a translation scheme that serves as a reference.")

  parser.add_argument("--from-csv", action = 'store',
      help="Plotting only -- read results from csv file.")

  parser.add_argument("--to-csv", action='store', default='',
      help="Specify name of of a csv file.")

  # NOTE: changing the equivalence notions would break normalization and plotting.
  #parser.add_argument("--verify", nargs='+', default='', action = 'store', 
  #    metavar = '<str>', help="Specify verification methods: \
  #        (bisimulation, pathway, integrated, bisim-loop-search,\
  #        bisim-depth-first, bisim-whole-graph)") 

  parser.add_argument("--verify-timeout", type=int, default=30,
      help="Specify time [seconds] to wait for verification to complete.")

  parser.add_argument("--pyplot", default='', action = 'store',
      help="Specify name of plot file. Choose from fileformats *.pdf or *.png")

  parser.add_argument("-v", "--verbose", action='count', default=0,
      help="Print more output (-vv for extra debugging information)")

  return

def get_peppercorn_args(parser):
  """Selected arguments for the peppercorn interface. """
  parser.add_argument('--max-complex-size', default=100, type=int, dest='MAX_COMPLEX_SIZE', 
      metavar='<int>',
      help="Peppercorn: Maximum number of strands allowed in a complex" + \
          "(used to prevent polymerization)")
  parser.add_argument('--max-complex-count', default=10000, type=int, dest='MAX_COMPLEX_COUNT',
      metavar='<int>',
      help="Peppercorn: Maximum number of complexes that may be enumerated" + \
          "before the enumerator halts.")
  parser.add_argument('--max-reaction-count', default=10000, type=int, dest='MAX_REACTION_COUNT',
      metavar='<int>',
      help="Peppercorn: Maximum number of reactions that may be enumerated " + \
          "before the enumerator halts.")

  parser.add_argument('--reject-remote', action='store_true', dest='REJECT_REMOTE',
      help="Peppercorn: Discard remote toehold mediated 3-way and 4-way branch migration reactions.")
  parser.add_argument('--ignore-branch-3way', action='store_true',
      help="Peppercorn: Ignore 3-way branch migration events during enumeration.")
  parser.add_argument('--ignore-branch-4way', action='store_true',
      help="Peppercorn: Ignore 4-way branch migration events during enumeration.")

  # TODO: explain these options in more detail!
  parser.add_argument('--release-cutoff-1-1', type=int, default=6, dest='RELEASE_CUTOFF_1_1',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously "+\
          "in a 1-1 `open` reaction" )
  parser.add_argument('--release-cutoff-1-n', type=int, default=6, dest='RELEASE_CUTOFF_1_N',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously " + \
          "in a 1-n `open` reaction.")
  parser.add_argument('--release-cutoff', type=int, default=None, dest='RELEASE_CUTOFF',
      metavar='<int>',
      help="Peppercorn: Maximum number of bases that will be released spontaneously " +\
          "in an `open` reaction, for either 1-1 or 1-n reactions (equivalent to setting " + \
          "--release-cutoff-1-1 and --release-cutoff-1-n to the same value)")

  parser.add_argument('--no-max-helix', action='store_true',
      help="Peppercorn: Don't apply 'max helix at a time' semantics to " +\
          "3-way branch migration reactions.")
  parser.add_argument('--legacy-unzip', action='store_true', dest='LEGACY_UNZIP',
      help="Peppercorn: Apply legacy 'UNZIP=True' behavior. Note: --legacy-unzip" + \
      "mode will have no effect, if max helix semantics are disabled (--no-max-helix)")

  parser.add_argument('--enum-detailed', action='store_true',
      help="Peppercorn: Return detailed reaction network, rather than condensed reactions.")

  parser.add_argument('--k-slow', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be discarded")

  parser.add_argument('--k-fast', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be marked as slow")

  return

if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  get_nuskellCMP_args(parser)
  get_peppercorn_args(parser)
  args = parser.parse_args()

  main(args)

