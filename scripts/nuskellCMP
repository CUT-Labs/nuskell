#!/usr/bin/env python

import os
import sys
import argparse
import pkg_resources
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from numpy import nan

from nuskell import translate, verify, reset_names, NuskellExit, __version__
from nuskell.parser import parse_crn_string, split_reversible_reactions
from nuskell.enumeration import TestTubePeppercornIO
from nuskell.verifier import removeSpecies, modular_bisimulation

def compare_schemes(reactions, schemedir, 
    crn_name = True,
    pc_args = None, 
    vnotions = ['pathway', 'bisimulation'],
    modular = False,
    vtime = 30, 
    cmp_ecrn_size = True,
    cmp_total_nuc = True,
    verbose=0):
  """Compare schemes for (multiple) CRNs.

  Arguments:
    reactions (list[str]): A list of CRN stings.
    schemedir (str): A path to a directory with translation schemes.
    vtime (int): Timeout of verification [seconds]
    args (argparse()): An object that contains arguments for peppercorn.

  Note: This function contains hacks ... not production ready
    * reject-remote hack for soloveichik-like schemes
    * number of nucleotides is wrong for schemes with history domains.
  
  """

  plotdata = [] # Scheme, CRN, Cost, Speed
  for (crn,crn_name) in reactions : 
    for scheme in sorted(os.listdir(schemedir)) :
      if scheme[-3:] != '.ts' : 
        print "\n# Ignoring file:", args.ts_dir + scheme
        continue

      if crn_name :
        current = [scheme, str(crn_name)]
      else :
        current = [scheme, crn]

      fcrn, fs, _, _ = parse_crn_string(crn) 
      fcrm = map(lambda x: split_reversible_reactions([x]), fcrn) # formal chemical reaction module
      fcrn = split_reversible_reactions(fcrn)

      print "\n# -------"
      print '# Scheme:', scheme, 'CRN:', crn
      print "# -------"
      try :
        reset_names()
        solution, modules = translate(crn, schemedir + scheme, 
            modular = modular,
            verbose = (verbose > 1)) 
      except NuskellExit, e:
        print '# ERROR:', e
        current.extend([None, None, None, None, None])
        plotdata.append(current)
        continue

      fuels = map(str, solution.present_complexes(exclude=fs))

      # NOTE: Peppercorn can raise a variety of errors, but almost all of them
      # come down to problems with --reject-remote semantics... here are a few
      # examples:
      notion = ['d'] if pc_args.enum_detailed else ['c']
      try :
        solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
      except RuntimeError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except TypeError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except IndexError, e:
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False
      except Exception, e:
        # Scheme: lakin2016_3D.ts CRN: A + A -> B + A
        # File "../peppercorn/utils.py", line 879, in check_structure
        # Exception: In complex 17029, incoherent structure at (0, 5) -> (1, 0)
        pc_args.REJECT_REMOTE = True
        solution.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed)
        notion.append('rr')
        pc_args.REJECT_REMOTE = False

      current.append(notion)

      interpret = solution.interpret_species(fs, prune=True)

      icrn = []
      # Implementation CRN is an enumerated CRN after regex-complexes have been removed.
      for r in solution.reactions:
        if args.verbose:
          print r, "[{} {} - {}]".format(r.rate, r.rateunits, r.rtype)
        rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
        icrn.append(rxn)

      # IMPLEMENTATION DETAILS
      print "# Enumerated system: {} species, {} reactions".format(
          len(solution.complexes), len(icrn))
      print "#  - {} signal species".format(
          len([c for c in solution.complexes if c.name in interpret.keys()]))
      print "#  - {} fuel species".format(
          len([c for c in solution.complexes if c.name in map(str, fuels)]))
      print "#  - {} intermediate species".format(
          len([c for c in solution.complexes if c.name not in (interpret.keys() + map(str,fuels))]))
      print '# Number of distinct strands in the system:', len(solution.strands)
      print '# Length of all distinct strands in the system:', sum(
          sum(map(lambda d: d.length, s)) for s in solution.strands.values())
      
      # NOTE: New code.. to do the module enumeration:
      if modular:
        seen_intermed = set()
        intermediates = filter(lambda x: x.name[0] == 'e', solution.complexes)
        module_crns = []
        for e, module in enumerate(modules) :
          # first, replace history complexes with their interpretation!
          for cplx in module.complexes:
            # TODO quite inefficient loops
            for k, v in interpret.items():
              if (cplx.name in v) and k != cplx.name :
                [newc] = solution.selected_complexes([k])
                module.add_complex(newc, solution.get_complex_concentration(newc))
                if module.has_complex(cplx):
                  module.rm_complex(cplx)

          # then, enumerate!
          if 'rr' in notion :
            pc_args.REJECT_REMOTE = True
            module.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed, prefix='tmp')
            pc_args.REJECT_REMOTE = False
          else:
            module.enumerate_reactions(pc_args, condensed = not pc_args.enum_detailed, prefix='tmp')

          # after enumeration, rename all tmp species with e species names in solution.
          for cplx in module.complexes:
            if cplx.name[:3] == 'tmp':
              replaced = False
              debugging = 0
              # TODO also quite inefficient
              while (not replaced):
                for x in intermediates:
                  if (cplx.sequence, cplx.structure) == (x.sequence, x.structure):
                    cplx.name = x.name
                    seen_intermed.add(x)
                    replaced = True
                    break
                cplx.rotate_once
                if debugging > len(cplx.lol_sequence):
                  raise RuntimeError("couldn't find enumerated species")
                debugging += 1

          # append the CRN 
          mcrn = []
          for r in module.reactions:
            rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
            mcrn.append(rxn)
          module_crns.append(mcrn)

        # last, identify crosstalk as the last implementation CRN (without formal correspondence)
        crosstalk = set()
        for x in intermediates :
          if x not in seen_intermed :
            RG = solution.ReactionGraph
            for react in RG.successors(x) + RG.predecessors(x):
              crosstalk.add(react)

        # append the CRN 
        mcrn = []
        for r in crosstalk :
          rxn = [map(str,r.reactants),map(str,r.products), [r.rate]]
          mcrn.append(rxn)
        if mcrn: module_crns.append(mcrn)

        icrns = map(lambda x: removeSpecies(x, map(str,fuels)), module_crns)

      # VERIFICATION
      vcrn = removeSpecies(icrn, fuels)
      for meth in vnotions :
        if 'modular-' in meth:
          # NOTE: Temporary to fixe a bug in testModules
          import copy
          backup = copy.deepcopy(interpret) if interpret else None
          v, _ = modular_bisimulation(fcrm, icrns, fs, interpret=backup, method=meth[8:],
              verbose=(verbose>1), timeout=vtime)
        else :
          v, _ = verify(fcrn, vcrn, fs, interpret=interpret, method=meth,
              verbose=(verbose>1), timeout=vtime)

        if v is True:
          print "# {}: CRNs are {} equivalent.".format(v, meth)
          current.append(v)
        elif v is False:
          print "# {}: CRNs are not {} equivalent.".format(v, meth)
          current.append(v)
        elif v is None:
          print "# {}: {} verification did not terminate within {} seconds.".format(v, meth, vtime)
          current.append(v)
          #current.append('- [{} s]'.format(vtime))

      if cmp_total_nuc :
        cost = sum(sum(map(lambda d: d.length, s)) for s in solution.strands.values())
        current.append(cost)

      if cmp_ecrn_size:
        speed = len(icrn)
        current.append(speed)

      plotdata.append(current)
  return plotdata

def normalize(rawdata, refscheme, ns=5):
  """Normalize results to reference scheme. 

    Note: This function requires a particular format of 'rawdata'. 
      You might have to adapte the code if you change verification...
  """
  normdata = []
  norm_values = filter(lambda x: x[0] == refscheme, rawdata)
  for n in norm_values: # A particular CRN
    current = filter(lambda x: x[1] == n[1], rawdata)
    for c in current:
      normdata.append(c[:ns] + [float(x)/y for x,y in zip(n[ns:], c[ns:])])
    
  return normdata

def single_plot(df, pfile='nuskell_compare.pdf', ts_order=None, crn_order=None):
  if not ts_order:
    ts_order = sorted(set(df['Translation scheme']), 
        key=lambda x: list(df['Translation scheme']).index(x))
  if not crn_order:
    crn_order = sorted(set(df['CRN']),
        key=lambda x: list(df['CRN']).index(x))

  marks=['^','+','x','<','>','d','s','p','_', '*', 
      '.', 'h', 'v', 'p', '1', '2', '3', '4', '8', '_']

  marks = marks[:len(ts_order)]

  g = sns.lmplot(data=df, x="reactions in condensed network", y="number of nucleotides", 
      hue="Translation scheme", hue_order = ts_order,
      #col="equivalent", col_wrap=2, col_order=[True, False, 'timeout'],
      #col="CRN", col_wrap=2, col_order=crn_order,
      legend=False, legend_out=True,
      #size=3.6,
      x_jitter=0.2,
      markers=marks,
      fit_reg=False,
      scatter=True)

  g = g.add_legend() #bbox_to_anchor=(1.63, 0.53))
  plt.savefig(pfile, bbox_inches="tight")
  return

def main(args):
  """Compare multiple tranlation schemes for a given CRN. """

  # *************** #
  # Check arguments #
  # _______________ #

  if args.pyplot and (args.pyplot[-4:] not in ('.pdf', '.png', '.eps')):
    raise SystemExit('Please choose a file format (*.pdf, *png, *eps) for your plot: {}'.format(
      args.pyplot))

  if not args.modular:
    args.modular = any(map(lambda x: 'modular' in x, args.verify))

  # ***************** #
  # Process CSV input #
  # _________________ #

  if args.from_csv :
    print '# Parsing data from file ... '
    df = pd.DataFrame().from_csv(args.from_csv)

  else:
    # ***************** #
    # Process CRN input #
    # _________________ #
    if args.crn_dir:
      print "Compiling CRNs in:", args.crn_dir
      reactions = []
      for crnfile in filter(lambda x: x[-4:] == '.crn', os.listdir(args.crn_dir)):
        print ' *', crnfile
        with open(args.crn_dir+crnfile) as fcrn :
          react = ''
          for l in fcrn.readlines():
            react += l.strip() + '; '
        reactions.append((react[:-2], crnfile))
    else :
      input_crn = sys.stdin.readlines()
      input_crn = "".join(input_crn).strip()
      reactions = [(input_crn, input_crn)]
      print "Compiling CRN:"
      for (rxn, n) in reactions: 
        print ' *', rxn
      print

    # **************** #
    # Process TS input #
    # ________________ #

    if args.ts_dir :
      print "Comparing schemes in:", args.ts_dir
    else :
      print "Comparing default schemes:" 
      args.ts_dir = pkg_resources.resource_filename('nuskell', 'schemes') + '/'

    for ts in filter(lambda x: x[-3:] == '.ts', sorted(os.listdir(args.ts_dir))):
      print ' *', ts

    # ***************** #
    # Process REF input #
    # _________________ #
    
    if args.reference and args.reference not in os.listdir(args.ts_dir):
      raise Exception('Reference scheme not found.')

    # ********* #
    # MAIN LOOP #
    # _________ #

    plotdata = compare_schemes(reactions, args.ts_dir,
        pc_args = args,
        cmp_ecrn_size = True,
        cmp_total_nuc = True,
        vnotions = args.verify,
        modular = args.modular,
        vtime = args.verify_timeout,
        verbose=args.verbose)

    # Results:
    idx = zip(zip(*plotdata)[0], zip(*plotdata)[1])
    df = pd.DataFrame(plotdata, index=idx, 
        columns=[
          'Translation scheme', 'CRN', 'enumerated'] + args.verify + [
          'number of nucleotides', 'reactions in condensed network'])

  #print 'Rawdata:'
  #print df.to_string(index=False, justify='left')
  #print df.to_latex(index=False)

  # Save to portable format:
  if args.to_csv:
    df.to_csv(path_or_buf=args.to_csv)

  # Normalize data to --reference scheme
  # TODO: remove csv dependece
  if not args.from_csv and args.reference :
    plotdata = normalize(plotdata, args.reference)
    print 'Normalized to {}:'.format(args.reference)
    df = pd.DataFrame(plotdata, 
        columns=[
          'Translation scheme', 'CRN', 'enumerated'] + args.verify + [
          'number of nucleotides', 'reactions in condensed network'])
    print df.to_string(index=False, justify='right')

  def equiv(x):
    if True in x :
      return True
    elif (nan in x) or (None in x) :
      return 'timeout'
    else :
      return False

  # Add column that combines pathway and bisimulation notion 
  e = map(equiv, zip(*map(lambda x: df[x], args.verify)))
  df['equivalent'] = e
  print df.to_string(index=False, justify='left')

  if args.pyplot :
    single_plot(df, pfile=args.pyplot)

def get_nuskellCMP_args(parser) :
  """ A collection of arguments for Nuskell """
  parser.add_argument('--version', action='version', version='%(prog)s ' + __version__)
  parser.add_argument("-v", "--verbose", action='count', default=0,
      help="print verbose output. -vv increases verbosity level.")

  input = parser.add_argument_group('NuskellCMP Input Arguments')

  input.add_argument("--ts-dir", action = 'store', metavar='<path/to/dir>', 
      help="""Specify path to the translation scheme directory. Only files that
      have a *.ts ending will be compared.""")

  input.add_argument("--crn-dir", action = 'store', metavar='<path/to/dir>', 
      help="""Specify path to a CRN directory. Only files that have a *.crn
      ending will be compared.""")

  input.add_argument("--reference", action = 'store', metavar='<path/to/file>', 
      help="Specify a translation scheme that serves as a reference.")

  input.add_argument("--from-csv", action = 'store', metavar='<path/to/file>', 
      help="Read results from a *.CSV file. All other inputs are ignored.")

  default = parser.add_argument_group('NuskellCMP Output Arguments')

  default.add_argument("--pyplot", default='', action = 'store', metavar='<path/to/file>', 
      help="Specify name of plot file. Choose from fileformats *.pdf or *.png")

  default.add_argument("--to-csv", action='store', default='', metavar='<path/to/file>', 
      help="Print results to a *.CSV file.")

  # NOTE: changing the equivalence notions would break normalization and plotting.
  default.add_argument("--verify", nargs='+', default=['bisimulation', 'pathway'], 
      action = 'store', 
      choices=('bisimulation', 'pathway', 'integrated', 'modular-bisimulation',
      'bisim-loop-search', 'bisim-depth-first', 'bisim-whole-graph',
      'modular-bisim-loop-search',
      'modular-bisim-depth-first', 
      'modular-bisim-whole-graph'), 
      metavar='<str>', 
      help="""Specify verification methods. Choose one or more
      from: bisimulation, pathway, integrated, modular-bisimulation,
      bisim-loop-search, bisim-depth-first, bisim-whole-graph,
      modular-bisim-loop-search,
      modular-bisim-depth-first, 
      modular-bisim-whole-graph.""") 

  default.add_argument("--modular", action='store_true',
      help="""After enumeration of the full system, enumerate individual CRN
      modules separately, to identify crosstalk between reactions. This is
      turned on automatically when using modular-bisimulation verification.""")

  default.add_argument("--verify-timeout", type=int, default=30, metavar='<int>',
      help="Specify time in seconds to wait for verification to complete.")

  return parser

def get_peppercorn_args(parser):
  """Selected arguments for the peppercorn interface. """
  peppercorn = parser.add_argument_group('Peppercorn Reaction Enumerator Arguments')
  peppercorn.add_argument('--max-complex-size', default=100, type=int,
      dest='MAX_COMPLEX_SIZE', metavar='<int>', 
      help="""Maximum number of strands allowed in a complex (used to prevent
      polymerization)""")
  peppercorn.add_argument('--max-complex-count', default=1000, type=int,
      dest='MAX_COMPLEX_COUNT', metavar='<int>',
      help="""Maximum number of complexes that may be enumerated before the enumerator halts.""")
  peppercorn.add_argument('--max-reaction-count', default=10000, type=int,
      dest='MAX_REACTION_COUNT', metavar='<int>',
      help="""Maximum number of reactions that may be enumerated before the
      enumerator halts.""")

  peppercorn.add_argument('--reject-remote', action='store_true', dest='REJECT_REMOTE',
      help="Discard remote toehold mediated 3-way and 4-way branch migration reactions.")
  peppercorn.add_argument('--ignore-branch-3way', action='store_true',
      help="Ignore 3-way branch migration events during enumeration.")
  peppercorn.add_argument('--ignore-branch-4way', action='store_true',
      help="Ignore 4-way branch migration events during enumeration.")

  # TODO: explain these options in more detail!
  peppercorn.add_argument('--release-cutoff-1-1', type=int, default=6, dest='RELEASE_CUTOFF_1_1',
      metavar='<int>', 
      help="""Maximum number of bases that will be released spontaneously in a
      1-1 `open` reaction""")
  peppercorn.add_argument('--release-cutoff-1-n', type=int, default=6, dest='RELEASE_CUTOFF_1_N',
      metavar='<int>',
      help="""Maximum number of bases that will be released spontaneously in a
      1-n `open` reaction.""")
  peppercorn.add_argument('--release-cutoff', type=int, default=None, dest='RELEASE_CUTOFF',
      metavar='<int>',
      help="""Maximum number of bases that will be released spontaneously in an
      `open` reaction, for either 1-1 or 1-n reactions (equivalent to setting
      --release-cutoff-1-1 and --release-cutoff-1-n to the same value)""")

  peppercorn.add_argument('--no-max-helix', action='store_true',
      help="""Do not apply 'max helix at a time' semantics to 3-way branch
      migration reactions.""")

  peppercorn.add_argument('--legacy-unzip', action='store_true', dest='LEGACY_UNZIP',
      help="""Apply legacy 'UNZIP=True' behavior. Note: --legacy-unzip will
      have no effect, if max helix semantics are disabled (--no-max-helix)""")

  # NOTE: Output formatting: this option is not directly passed on to peppercorn
  peppercorn.add_argument('--enum-detailed', action='store_true',
      help="Do not condense reactions into only resting complexes")

  peppercorn.add_argument('--k-slow', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be discarded")

  peppercorn.add_argument('--k-fast', default=0.0, type=float, metavar='<flt>',
      help="Unimolecular reactions slower than this rate will be marked as slow")

  return parser

if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  get_nuskellCMP_args(parser)
  get_peppercorn_args(parser)
  args = parser.parse_args()

  main(args)

