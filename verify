#!/usr/bin/env python
#
#
# Copyright (c) 2009-2015 Caltech. All rights reserved.
# Written by Seung Woo Shin (seungwoo.theory@gmail.com)
#
#
# Verifier executable.
#

import sys, compiler, crn_parser, dom_parser, random, os, crn_bisimulation_equivalence, crn_pathway_equivalence, string, copy, enumerator.input as enumerator_in, enumerator.output as enumerator_out, argparse, enumerator.reactions as reactions

def find(l, key):
    for i in range(len(l)):
        if l[i] == key:
            return i
    return None

def rotate(complex):
    def hardcopyList(l):
        if type(l) != list:
            return l
        return map(hardcopyList, l)

    complex = hardcopyList(complex)

    if "+" not in complex[0]:
        return complex        
    else:
        p = find(complex[0], "+")
        dom = complex[0][p + 1:] + ["+"] + complex[0][:p]

        # change parentheses appropriately
        dpr = complex[1]
        stack = []
        for i in range(p):
            if dpr[i] == "(": stack.append(i)
            elif dpr[i] == ")": stack.pop()
        for i in stack:
            dpr[i] = ")"
        stack = []
        for i in reversed(range(p + 1, len(dpr))):
            if dpr[i] == ")": stack.append(i)
            elif dpr[i] == "(": stack.pop()
        for i in stack:
            dpr[i] = "("
        
        dpr = dpr[p + 1:] + ["+"] + dpr[:p]
        return [dom, dpr]

def patternMatch(x, y):
    if "+" in x[0]:
        if "+" not in y[0]:
            return False
        px = find(x[0], "+")
        py = find(y[0], "+")
        return patternMatch([x[0][:px], x[1][:px]],
                            [y[0][:py], y[1][:py]]) and \
               patternMatch([x[0][px + 1:], x[1][px + 1:]],
                            [y[0][py + 1:], y[1][py + 1:]])

    if len(x[0]) == 0:
        if len(y[0]) > 0:
            return False
        else:
            return True

    if x[0][0] != "?":
        if len(y[0]) == 0 or x[0][0] != y[0][0] or x[1][0] != y[1][0]:
            return False
        else:
            return patternMatch([x[0][1:], x[1][1:]],
                                [y[0][1:], y[1][1:]])
    else:
        for i in range(len(y) + 1):
            if patternMatch([x[0][1:], x[1][1:]],
                            [y[0][i:], y[1][i:]]):
                return True
        return False

def removeFuels(crn, fuel):
    crn = [[filter(lambda s: s not in fuel, rxn[0]),
            filter(lambda s: s not in fuel, rxn[1])]
           for rxn in crn]
    return crn

def remove_duplicates(l):
    r = []
    if len(l) == 0: return []
    l.sort()
    while len(l) > 1:
        if l[0] != l[1]:
            r.append(l[0])
        l = l[1:]
    r.append(l[0])
    return r

def enumarg(enum):
	# Parse command-line arguments
	parser = argparse.ArgumentParser(description="""
		Peppercorn: Domain-level nucleic acid reaction enumerator. See README.{html, pdf} for usage examples.
		""")
	parser.add_argument('--max-complex-size', '--complex-size', action='store', dest='MAX_COMPLEX_SIZE', default=enum.MAX_COMPLEX_SIZE, type=int, \
		help="Maximum number of strands allowed in a complex (used to prevent polymerization) (default: %(default)s)")
	parser.add_argument('--max-complex-count', '--max-complexes', action='store', dest='MAX_COMPLEX_COUNT', default=enum.MAX_COMPLEX_COUNT, type=int, \
		help="Maximum number of complexes that may be enumerated before the enumerator halts. (default: %(default)s)")
	parser.add_argument('--max-reaction-count', '--max-reactions', action='store', dest='MAX_REACTION_COUNT', default=enum.MAX_REACTION_COUNT, type=int, \
		help="Maximum number of reactions that may be enumerated before the enumerator halts. (default: %(default)s)")

	parser.add_argument('--release-cutoff-1-1', action='store', dest='RELEASE_CUTOFF_1_1', type=int, \
		help="Maximum number of bases that will be released spontaneously in a 1-1 `open` reaction (default: %d)" % reactions.RELEASE_CUTOFF_1_1)
	parser.add_argument('--release-cutoff-1-n', action='store', dest='RELEASE_CUTOFF_1_N', type=int, \
		help="Maximum number of bases that will be released spontaneously in a 1-n `open` reaction. (default: %d)" % reactions.RELEASE_CUTOFF_1_N)
	parser.add_argument('--release-cutoff', action='store', dest='RELEASE_CUTOFF', default=None, type=int, \
		help="Maximum number of bases that will be released spontaneously in an `open` reaction, for either 1-1 or 1-n reactions (equivalent to setting --release-cutoff-1-1 and --release-cutoff-1-n to the same value)")

	parser.add_argument('--k-slow', action='store', dest='k_slow', default=0.0, type=float, \
		help="Unimolecular reactions slower than this rate will be discarded (default: %(default)f)")
	parser.add_argument('--k-fast', action='store', dest='k_fast', default=0.0, type=float, \
		help="Unimolecular reactions slower than this rate will be marked as slow (default: %(default)f)")

	parser.add_argument('--reject-remote', action='store_true', dest='REJECT_REMOTE', default=False, \
		help="Discard remote toehold mediated 3-way and 4-way branch migration reactions. (default: %(default)s)")
	parser.add_argument('--no-max-helix', action='store_false', dest='UNZIP', default=True, \
		help="Don't apply 'max helix at a time' semantics to 3-way branch migration reactions. (default: False)")
	parser.add_argument('--legacy-unzip', action='store_true', dest='LEGACY_UNZIP', default=False, \
		help="Apply legacy 'UNZIP=True' behavior; no effect with --no-max-helix (default: %(default)s)")

	parser.add_argument('--bfs-ish', action='store_true', dest='bfs', \
		help="When searching for bimolecular reactions, look to the oldest complexes first. (default: %(default)s)")
	parser.add_argument('--ignore-branch-3way', action='store_true', dest='ignore_branch_3way', \
		help="Ignore 3-way branch migration events during enumeration.  (default: %(default)s)")
	parser.add_argument('--ignore-branch-4way', action='store_true', dest='ignore_branch_4way', \
		help="Ignore 4-way branch migration events during enumeration.  (default: %(default)s)")


	parser.add_argument('--profile', action='store_true', dest='profile',\
		help="Enable statistical profiling")
	cl_opts, unknown = parser.parse_known_args()

	# Transfer options to enumerator object
	if cl_opts.k_slow is not None:
		enum.k_slow = cl_opts.k_slow
	if cl_opts.k_fast is not None:
		enum.k_fast = cl_opts.k_fast

	if cl_opts.MAX_REACTION_COUNT is not None:
		enum.MAX_REACTION_COUNT = cl_opts.MAX_REACTION_COUNT

	if cl_opts.MAX_COMPLEX_COUNT is not None:
		enum.MAX_COMPLEX_COUNT = cl_opts.MAX_COMPLEX_COUNT

	if cl_opts.MAX_COMPLEX_SIZE is not None:
		enum.MAX_COMPLEX_SIZE = cl_opts.MAX_COMPLEX_SIZE

	if cl_opts.RELEASE_CUTOFF is not None:
		enum.RELEASE_CUTOFF = cl_opts.RELEASE_CUTOFF

	if cl_opts.RELEASE_CUTOFF_1_1 is not None:
		enum.RELEASE_CUTOFF_1_1 = cl_opts.RELEASE_CUTOFF_1_1

	if cl_opts.RELEASE_CUTOFF_1_N is not None:
		enum.RELEASE_CUTOFF_1_N = cl_opts.RELEASE_CUTOFF_1_N

	if cl_opts.REJECT_REMOTE is not None:
		enum.REJECT_REMOTE = cl_opts.REJECT_REMOTE

	if cl_opts.UNZIP is not None:
		enum.UNZIP = cl_opts.UNZIP

	if cl_opts.LEGACY_UNZIP is not None:
		enum.LEGACY_UNZIP = cl_opts.LEGACY_UNZIP

	enum.DFS = not cl_opts.bfs

	# Modify enumeration events based on command line options.
	if cl_opts.ignore_branch_3way:
			if reactions.branch_3way in enum.FAST_REACTIONS:
					enum.FAST_REACTIONS.remove(reactions.branch_3way)

	if cl_opts.ignore_branch_4way:
			if reactions.branch_4way in enum.FAST_REACTIONS:
					enum.FAST_REACTIONS.remove(reactions.branch_4way)

def test(crnfile, domfile, method, interactive = False, condense = True, verbose = True):
    # Parse the crn
    (old_crn, fs, cs_waste) = crn_parser.parse_file(crnfile)       # fs is the set of formal species
    t = old_crn
    old_crn = []
    for [x, r, p] in t:
        old_crn.append([r,p])
        if x == "reversible":
            old_crn.append([p,r])

    # Parse the dom
    tfile = "".join(random.sample(string.letters + string.digits, 8)) + "._tmp"
    dom = dom_parser.parse(domfile)

    # Generate an input file for state enumerator
    F = open(tfile, "w")
    if len(dom) == 2:   # there is sequence information
        complexes = dom[1]
        for i in dom[0]:
            print >> F, "domain", i[0], ":", i[1]
    else:
        complexes = dom[0]
    print >> F, "domain dummy : 15"

    strand_n = 0
    out_strands = {}
    out_complexes = []

    for i in complexes:
        c = [i[0],"",""]
        s = ""
        i[1].append("+")
        for j in i[1]:
            if j == "?":
                s += " dummy"
            if type(j) == list:
                if len(j) == 2:
                    j = j[0] + j[1]
                else:
                    j = j[0]
                s += " " + j
            elif j == "+":
                if s not in out_strands.keys():
                    strand_n += 1
                    sname = "strand"+str(strand_n)
                    out_strands[s] = sname
                else:
                    sname = out_strands[s]
                s = ""
                c[1] += " "+sname
        i[1] = i[1][:-1]
        for j in i[2]:
            if j == "+": j = " + "
            c[2] += j
        out_complexes.append(c)

    for s in out_strands.keys():
        sname = out_strands[s]
        print >> F, "strand", sname, ":", s

    for [c0,c1,c2] in out_complexes:
        print >> F, "complex", c0, ":"
        print >> F, c1
        print >> F, c2
        print >> F
    F.close()

    # constant species
    cs = map(lambda x: x[0], complexes)
    cs = filter(lambda x: x not in fs, cs)

    #
    # call state enumerator
    #
    enumerator = enumerator_in.input_enum(tfile)
    enumerator.MAX_COMPLEX_COUNT = 10000
    enumerator.MAX_REACTION_COUNT = 50000
    enumerator.MAX_COMPLEX_SIZE = 100
    #enumerator.k_fast = 2.0
    #enumerator.REJECT_REMOTE = True
    enumarg(enumerator)
    enumerator.enumerate()
    enumerator_out.output_crn(enumerator,tfile, output_condensed = condense)
    F = open(tfile, "r")
    new_crn = []
    for line in F:
        line = line.split("->")
        line[0] = line[0].split("+")
        line[1] = line[1].split("+")
        line[0] = map(lambda x: x.strip(), line[0])
        line[1] = map(lambda x: x.strip(), line[1])
        line[0] = sorted(line[0])
        line[1] = sorted(line[1])
        new_crn.append(line)
    F.close()
    # delete the temporary file
    filelist = [ f for f in os.listdir(".") if f.endswith("._tmp") ]
    for f in filelist:
        os.remove(f)

    # convert the output from state enumerator to cmpdna format
    slow_complexes = []
    for z in enumerator.resting_states:
        name = str(z)
        for y in z.complexes:
            y1 = []
            for x in y.strands:
                y1.append("+")
                for w in x.domains:
                    w = str(w)
                    if w[-1] == "*":
                        y1.append([w[:-1], "*"])
                    else:
                        y1.append([w])
            if len(y1)>0: y1 = y1[1:]
            y = [name, y1, list(y.dot_paren_string())]
            slow_complexes.append(y)

    inter = {}
    dictionary = {}
    fsp = []
    rm = set()
    for x in complexes:
        if "?" not in x[1]:
            if x[0] in fs:
                inter[x[0]] = [x[0]]
                fsp.append(x[0])
            continue
        cnt = 0
        for y in slow_complexes:
            if x[0] == y[0]:
                dictionary[y[0]] = x[0] + "_i"
                if x[0] in fs:
                    inter[x[0]+"_i"] = [x[0]]
                    fsp.append(x[0]+"_i")
                continue
            original = x[1:]
            target = y[1:]
            if len(original[0]) != len(target[0]): continue
            p = rotate(target)
            while True:
                flag = True
                for i in range(len(original[0])):
                    if not ((original[0][i] == p[0][i] and original[1][i] == p[1][i]) or (original[0][i] == "?" and p[1][i] == ".")):
                        flag = False
                if flag:
                    cnt += 1
                    dictionary[y[0]] = x[0] + "_" + str(cnt)
                    if x[0] in fs:
                        inter[x[0]+"_"+str(cnt)] = [x[0]]
                        fsp.append(x[0]+"_"+str(cnt))
                        rm.add(x[0]+"_i")
                    break
                if p == target:
                    break
                p = rotate(p)

    for i in range(len(new_crn)):
        [reactants, products] = new_crn[i]
        def get_name(x):
            if x in dictionary.keys():
                x = dictionary[x]
            return x
        reactants = map(get_name, reactants)
        products = map(get_name, products)
        new_crn[i] = [reactants, products]
    
    # preprocess fuel
    new_crn = removeFuels(new_crn, cs)
    new_crn = sorted(map(lambda x: [sorted(x[0]), sorted(x[1])], new_crn))
    new_crn = remove_duplicates(new_crn)

    # removing initial signals that are unnecessary
    fsp = set(fsp)
    for x in rm:
        if x in inter.keys(): del inter[x]
        if x in fsp: fsp.remove(x)
    norm = set(fsp)-rm
    flag = None
    while flag != norm:
        flag = set(list(norm))
        for [r,p] in new_crn:
            if set(r).intersection(norm) == set(r):
                norm = norm.union(set(p))
    new_crn = filter(lambda x: set(x[0]).intersection(norm) == set(x[0]), new_crn)

    # fs = formal species; cs = fuels or constant species
    if method == "--bisimulation":
        return crn_bisimulation_equivalence.test((old_crn, fs), (new_crn, fs), verbose)#, inter)
    elif method == "--pathway":
        return crn_pathway_equivalence.test((old_crn, fs), (new_crn, fsp), inter, verbose, False, interactive)
    elif method == "--integrated":
        return crn_pathway_equivalence.test((old_crn, fs), (new_crn, fsp), inter, verbose, True, interactive)



if __name__ == "__main__":
    # The name of the program
    program_name = "verify"

    # Help message
    if "--help" in sys.argv:
        print "Usage: " + program_name + " TSFILE CRNFILE [OPTION]"
        print "Compile CRNFILE to DNA molecules using the translation scheme",
        print "from TSFILE and verify the result."
        print
        print "  --pathway      Use the compositional hybrid notion [default]."
        print "  --bisimulation Use the bisimulation equivalence notion."
        print "  --integrated   Use the integrated hybrid notion."
        print "  --interactive  Use interactive mode for hybrid approach."
        print "  --help         Output this help."
        print
        print "Report bugs to <seungwoo.theory@gmail.com>."
        exit()

    # Did I get a sufficient number of arguments?
    if len(sys.argv) < 3: # expects at least two arguments
        print program_name + ": missing operand after `" + program_name + "'"
        print program_name + ": try `" + program_name + " --help' for more information."
        exit()

    # Get the arguments.
    ts_file = sys.argv[1]
    crn_file = sys.argv[2]
    
    options = sys.argv[3:]
    method = None
    interactive = False
    if "--pathway" in options: method = "--pathway"
    if "--bisimulation" in options: method = "--bisimulation"
    if "--integrated" in options: method = "--integrated"
    if method == None: method = "--pathway" 
    if "--interactive" in options: interactive = True

    # Add the correct extensions if necessary.
    if len(ts_file) < 3 or ts_file[-3:] != ".ts": ts_file += ".ts"
    if len(crn_file) < 4 or crn_file[-4:] != ".crn": crn_file += ".crn"

    compiler.compile(ts_file, crn_file)
    v = test(crn_file, crn_file[:-4] + ".dom", method, interactive)

    if v:
        print "verify: compilation was correct."
    else:
        print "verify: compilation was incorrect."
